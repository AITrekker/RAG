# Use an official PyTorch image with CUDA 12.1, which is compatible with most modern NVIDIA GPUs.
# This image includes Python 3.11, CUDA, and cuDNN.
FROM pytorch/pytorch:2.3.1-cuda12.1-cudnn8-runtime

# Set environment variables
ENV PYTHONUNBUFFERED=1
ENV PYTHONDONTWRITEBYTECODE=1
ENV CUDA_VISIBLE_DEVICES=0

# Set working directory
WORKDIR /app

# The PyTorch image comes with torch, torchvision, and torchaudio pre-installed.
# We only need to install the remaining dependencies.

# Copy requirements file
COPY requirements.txt .

# Install Python dependencies using pip
# We exclude torch, torchvision, and torchaudio as they are already in the base image.
RUN pip install --no-cache-dir -r requirements.txt --break-system-packages

# Create necessary directories
RUN mkdir -p /app/data/chroma /app/data/uploads /app/cache/transformers /app/logs

# Copy application code
COPY src/backend /app/src/backend
COPY scripts /app/scripts

# Set Python path
ENV PYTHONPATH=/app/src/backend:$PYTHONPATH

# Create a non-root user for security and change ownership of the app directory
RUN useradd -m -u 1001 appuser && chown -R appuser:appuser /app
USER appuser

# Expose the application port
EXPOSE 8000

# Health check to ensure the service is running
HEALTHCHECK --interval=30s --timeout=10s --start-period=60s --retries=3 \
    CMD curl -f http://localhost:8000/health || exit 1

# Default command to run the application
CMD ["uvicorn", "src.backend.main:app", "--host", "0.0.0.0", "--port", "8000"] 