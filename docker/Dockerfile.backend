# Use the latest NVIDIA PyTorch container for RTX 5070 compatibility
FROM nvcr.io/nvidia/pytorch:24.12-py3

# Set up the working directory
WORKDIR /app

# Upgrade pip and install essential system packages
RUN pip install --upgrade pip && \
    apt-get update && apt-get install -y --no-install-recommends \
    build-essential \
    curl \
    git \
    && rm -rf /var/lib/apt/lists/*

# Copy requirements files
COPY requirements-base.txt .
COPY requirements.txt .
COPY constraints.txt .

# Install PyTorch with CUDA 12.8 support for RTX 5070 (sm_120)
# CRITICAL: This specific PyTorch version supports sm_120 (RTX 5070)
# DO NOT change this installation method or PyTorch will downgrade!
RUN --mount=type=cache,target=/root/.cache/pip \
    pip3 install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu128

# Install base requirements (heavyweight packages) 
# Use constraints file to prevent PyTorch downgrades and leverage cache
RUN --mount=type=cache,target=/root/.cache/pip \
    pip install --upgrade-strategy only-if-needed -c constraints.txt -r requirements-base.txt

# Install main requirements (lightweight packages)  
RUN --mount=type=cache,target=/root/.cache/pip \
    pip install --upgrade-strategy only-if-needed -c constraints.txt -r requirements.txt

# Test that ML libraries can be imported successfully and verify CUDA support
RUN python -c "import torch; print(f'PyTorch version: {torch.__version__}'); \
    print(f'CUDA available: {torch.cuda.is_available()}'); \
    print(f'CUDA version: {torch.version.cuda}'); \
    import transformers; print(f'Transformers version: {transformers.__version__}'); \
    print('Core ML libraries imported successfully!')"

# Copy the application source code
# Maintain the src/ structure for proper imports
COPY ./src /app/src
COPY ./scripts/ /app/scripts

# Create a non-root user for security.
# Note: In some GPU environments, root may be required.
# If issues arise, this may need to be commented out.
RUN addgroup --system app && adduser --system --group app

# Create necessary directories with proper permissions
RUN mkdir -p /app/logs /app/data /app/cache \
    /home/app/.cache/huggingface \
    /home/app/.cache/transformers && \
    chown -R app:app /app /home/app/.cache

USER app

# Set environment variables for Python
ENV PYTHONUNBUFFERED=1
ENV PYTHONPATH=/app
ENV HF_HOME=/home/app/.cache/huggingface
ENV TRANSFORMERS_CACHE=/home/app/.cache/transformers

# Expose the application port
EXPOSE 8000

# The CMD is now handled by docker-compose.yml to allow for easier
# overriding and script execution before the main app starts.
# Example CMD: ["uvicorn", "main:app", "--host", "0.0.0.0", "--port", "8000"]