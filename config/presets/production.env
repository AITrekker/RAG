# Production RAG Configuration
# Optimized for reliability, consistency, and performance at scale

# === LLM Configuration ===
RAG_LLM_MODEL=gpt2-medium
RAG_TEMPERATURE=0.3
RAG_MAX_NEW_TOKENS=200
RAG_MAX_LENGTH=512
RAG_TOP_P=0.85
RAG_TOP_K=40
RAG_REPETITION_PENALTY=1.3
RAG_DO_SAMPLE=true
RAG_EARLY_STOPPING=true
RAG_ENABLE_QUANTIZATION=true

# === Retrieval Configuration ===
RAG_MAX_SOURCES=5
RAG_CONFIDENCE_THRESHOLD=0.4
RAG_MAX_CONTEXT_LENGTH=2000
RAG_SOURCE_PREVIEW_LENGTH=200

# === Response Quality ===
RAG_MAX_SENTENCES=4
RAG_MIN_SENTENCE_LENGTH=10
RAG_REMOVE_PROMPT_ARTIFACTS=true
RAG_ENSURE_PUNCTUATION=true

# === Performance ===
RAG_CACHE_DIR=/app/cache/models
EMBEDDING_DEVICE=cpu
EMBEDDING_BATCH_SIZE=32