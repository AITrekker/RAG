# ğŸ¢ Enterprise RAG Platform

A production-ready, enterprise-grade Retrieval-Augmented Generation (RAG) platform with PostgreSQL + pgvector for unified storage and intelligent delta synchronization.

## âœ¨ Features

### ğŸ—ï¸ **Enterprise Architecture**
- **ğŸ”’ Multi-tenant Isolation**: Complete data separation across database and file system
- **ğŸ”„ Intelligent Delta Sync**: Hash-based change detection with simplified sequential processing
- **ğŸ—ƒï¸ Unified Storage**: PostgreSQL with pgvector for both metadata and high-performance vector operations
- **ğŸŒ API-First Architecture**: Comprehensive RESTful API with OpenAPI documentation
- **ğŸš€ Production Ready**: Container orchestration, health checks, and graceful degradation

### ğŸ“„ **Document Processing**
- **ğŸ“š Multi-Format Support**: PDF, DOCX, HTML, TXT, CSV with extensible processor architecture
- **ğŸ§© Smart Chunking**: Sentence-aware text splitting with configurable overlap and size
- **ğŸ” Content Extraction**: Intelligent text extraction with fallback mechanisms
- **ğŸ“Š Metadata Enrichment**: Automatic file analysis, word counts, language detection
- **ğŸ¦™ Hybrid LlamaIndex Integration**: Optional LlamaIndex for advanced document parsing with pgvector storage

### ğŸ§  **AI & Machine Learning**
- **ğŸ¯ Advanced RAG Pipeline**: Query processing â†’ Vector retrieval â†’ Context ranking â†’ LLM generation
- **ğŸ”€ Model Flexibility**: Configurable embedding models (sentence-transformers) and LLMs
- **âš¡ Performance Optimized**: Batch processing, caching, and async operations
- **ğŸ”„ Hybrid Processing**: LlamaIndex for complex documents, simple processing for basic files

### ğŸ” **Security & Compliance**
- **ğŸ”‘ API Key Authentication**: Stateless, secure tenant authentication
- **ğŸ“‹ Audit Trails**: Comprehensive operation tracking and sync history
- **ğŸ›¡ï¸ Input Validation**: Robust security with sanitization and rate limiting

## âš¡ Quick Start

### ğŸ“‹ Prerequisites
- **Docker** (24.0+) and **Docker Compose** (2.20+)
- **8GB+ RAM** (for ML models and vector operations)
- **2GB+ disk space** (for containers and model cache)

### ğŸš€ One-Command Deployment

```bash
git clone <repository-url>
cd rag
docker-compose up -d
```

This orchestrates all services:
- **ğŸ—„ï¸ PostgreSQL**: Multi-tenant database with pgvector for unified storage
- **âš™ï¸ Backend API**: FastAPI with comprehensive endpoints
- **ğŸ–¥ï¸ Frontend UI**: React-based management interface
- **ğŸ”§ Init Container**: Automatic database setup and admin user creation

### âœ… Verify Deployment

```bash
# Check all services are running
docker-compose ps

# View real-time logs
docker-compose logs -f

# Health check script
python scripts/verify_admin_setup.py
```

### ğŸŒ Access Your Platform

| Service | URL | Purpose |
|---------|-----|------------|
| **ğŸ–¥ï¸ Frontend Dashboard** | [localhost:3000](http://localhost:3000) | Main user interface |
| **ğŸ“š API Documentation** | [localhost:8000/docs](http://localhost:8000/docs) | Interactive API explorer |
| **ğŸ—„ï¸ Database** | `localhost:5432` | PostgreSQL with pgvector (external tools) |

### ğŸ¯ Quick Demo Setup

```bash
# Create demo tenants with sample documents
python scripts/workflow/setup_demo_tenants.py

# Test the complete RAG pipeline
python scripts/test_system.py

# Try sample queries
python demo_rag_queries.py
```

## ğŸ“š Architecture

### **ğŸ—ï¸ PostgreSQL + pgvector Architecture**

The platform uses a unified PostgreSQL + pgvector architecture for simplicity and performance:

```
PostgreSQL (Unified Storage)
â”œâ”€â”€ tenants & users
â”œâ”€â”€ files & metadata  
â”œâ”€â”€ embedding_chunks (with pgvector embeddings)
â”œâ”€â”€ sync operations
â”œâ”€â”€ access control
â””â”€â”€ audit trails
```

### **ğŸ” Service Layer Architecture**

Clean service layer pattern with simplified sync operations:

- **ğŸ”‘ Authentication Service**: API key authentication with tenant isolation
- **ğŸ“ File Management Service**: Upload, CRUD operations, metadata tracking
- **ğŸ”„ Delta Sync Service**: Hash-based change detection with sequential processing
- **ğŸ“„ Document Processing Service**: Multi-format extraction (PDF, HTML, TXT, DOCX) with hybrid LlamaIndex integration
- **ğŸ§  Embedding Service**: Sentence-transformers integration with pgvector storage
- **ğŸ” RAG Service**: Complete query processing, vector search, and answer generation with optional LlamaIndex synthesis

### File Storage Structure
```
data/
â”œâ”€â”€ uploads/
â”‚   â”œâ”€â”€ {tenant-id}/
â”‚   â”‚   â”œâ”€â”€ document1.pdf
â”‚   â”‚   â”œâ”€â”€ report.docx
â”‚   â”‚   â””â”€â”€ data.csv
â”‚   â””â”€â”€ {tenant-id-2}/
â”‚       â”œâ”€â”€ manual.pdf
â”‚       â””â”€â”€ notes.txt
```

### Database Schema
```sql
-- PostgreSQL Tables (Unified Storage)
â”œâ”€â”€ tenants                    # Tenant management & API keys
â”œâ”€â”€ users                      # User accounts
â”œâ”€â”€ files                      # File metadata & sync status
â”œâ”€â”€ embedding_chunks           # Text chunks with pgvector embeddings
â”œâ”€â”€ sync_operations           # Sync history & tracking
â””â”€â”€ file_access_control       # Access permissions
```

## ğŸ¦™ Hybrid LlamaIndex Integration

The platform features intelligent hybrid processing that combines the best of both worlds:

### **ğŸ¯ Smart Document Processing**
- **Complex Documents** (PDF, DOCX, HTML): Uses LlamaIndex for superior parsing and chunking
- **Simple Documents** (TXT): Uses lightweight internal processors for efficiency
- **Unified Storage**: All chunks stored in PostgreSQL + pgvector regardless of processing method

### **ğŸ”§ Graceful Fallbacks**
- LlamaIndex dependencies are **optional** - system works without them
- Automatic fallback to simple processing if LlamaIndex unavailable
- No architectural disruption when switching between modes

### **âš¡ Performance Benefits**
- LlamaIndex only used where it adds value (complex document parsing)
- Maintains simplified pgvector architecture for storage and retrieval
- Best-in-class document processing with streamlined vector operations

## ğŸ”„ Workflow

1. **ğŸ”‘ Authentication**: API key-based tenant authentication
2. **ğŸ“¤ File Upload**: Upload files via API or copy to tenant directories
3. **ğŸ”„ Delta Sync**: Sequential hash-based change detection and processing
4. **ğŸ§  Hybrid Processing**: LlamaIndex for complex docs, simple processing for basic files
5. **ğŸ—ƒï¸ Unified Storage**: All chunks stored in PostgreSQL + pgvector
6. **ğŸ” Query**: RAG queries with optional LlamaIndex response synthesis
7. **ğŸ“Š Results**: Rich answers with source citations and confidence scores

## ğŸ› ï¸ API Structure

### **ğŸ”‘ Authentication**
All API endpoints require authentication via API key:
```bash
# Header-based authentication
curl -H "X-API-Key: your-api-key" http://localhost:8000/api/v1/files

# Bearer token authentication  
curl -H "Authorization: Bearer your-api-key" http://localhost:8000/api/v1/files
```

### Core Endpoints
- **`/api/v1/health`** - System health checks
- **`/api/v1/files`** - File management with upload and CRUD operations  
- **`/api/v1/sync`** - Delta sync operations and change detection
- **`/api/v1/query`** - Complete RAG query processing with vector search
- **`/api/v1/auth`** - Tenant and API key management
- **`/api/v1/setup`** - System initialization
- **`/api/v1/admin`** - System administration

## ğŸ§ª Testing

```bash
# Setup demo tenants with API keys (run this first!)
python scripts/workflow/setup_demo_tenants.py

# Test complete RAG system (all components)
python scripts/test_rag_system.py

# Test simple RAG with PostgreSQL fallback
python scripts/test_rag_simple.py

# Test ML pipeline (embeddings + vector storage)
python scripts/test_ml_pipeline.py

# Test API endpoints and authentication
python scripts/test_api_endpoints.py
```

## ğŸ”§ Configuration

### Environment Variables
```bash
# Database
POSTGRES_HOST=localhost
POSTGRES_PORT=5432
POSTGRES_DB=rag_db
POSTGRES_USER=rag_user
POSTGRES_PASSWORD=rag_password

# API Settings
API_HOST=0.0.0.0
API_PORT=8000
LOG_LEVEL=INFO

# ML Settings
EMBEDDING_MODEL=sentence-transformers/all-MiniLM-L6-v2
NLTK_DATA=/tmp/nltk_data
```

## ğŸ“Š Monitoring

### Health Checks
- PostgreSQL database connectivity
- Document processing pipeline health
- RAG service component status

### Metrics
- RAG query performance and accuracy
- Document processing and sync operations
- Vector search response times
- System resource usage and error rates

## ğŸ”’ Security

- **API Key Authentication**: Secure tenant isolation
- **Input Validation**: Comprehensive request validation
- **Error Handling**: Secure error responses
- **Rate Limiting**: Configurable rate limits
- **Audit Logging**: Operation tracking

## ğŸš€ Deployment

### Docker Deployment
```bash
# Build and run with Docker Compose
docker-compose up -d

# Or build individual services
docker build -f docker/Dockerfile.backend -t rag-backend .
docker build -f docker/Dockerfile.frontend -t rag-frontend .
```

### Production Considerations
- Use external PostgreSQL with pgvector extension
- Configure ML model caching and GPU acceleration
- Set up monitoring for RAG query performance
- Implement backup strategies for the database
- Use HTTPS and proper authentication in production
- Consider scaling for large tenants

## ğŸ¤ Contributing

1. Fork the repository
2. Create a feature branch
3. Make your changes
4. Add tests
5. Submit a pull request

## ğŸ“„ License

This project is licensed under the MIT License - see the LICENSE file for details.

## ğŸ†˜ Support

For support and questions:
- Check the API documentation at `/docs`
- Open an issue on GitHub
- Contact the development team

---

## ğŸ“– Additional Documentation

### Key Commands (from CLAUDE.md)
- **Build**: `make backend-build` (fast container rebuild - ~6 minutes)
- **Full Rebuild**: `docker-compose build --no-cache` (with 6min timeout)
- **Container Management**: `docker-compose up -d`, `docker-compose down`

### Development Notes
- Backend builds take ~6 minutes due to HuggingFace/PyTorch cache copying
- ML model caches persist in Docker volumes for faster restarts
- Delta sync system uses PostgreSQL for control plane + pgvector for vectors
- Simplified sequential processing for reliability over performance optimization

### Current Architecture Status: âœ… WORKING
The PostgreSQL + pgvector delta sync architecture is fully implemented and tested with simplified, reliable sync operations.